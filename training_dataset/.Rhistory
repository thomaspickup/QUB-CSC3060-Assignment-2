ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Works out the proportion correct
proportion_correct <- nrow(ds.lt_di[correct_items,])/nrow(ds.lt_di)
# Works out the proportion incorrect
proportion_incorrect <- nrow(ds.lt_di[!correct_items,])/nrow(ds.lt_di)
# Logistic Regression Model fit
glm_fit <-glm(digit ~ V10, data = ds.lt_di, family = 'binomial')
# Works the predicted value based on the model created
ds.lt_di[["predicted_val"]] = predict(glm_fit, ds.lt_di, type="response")
# Zeroes out a predicted class field and then predicts based on a predicted value of 05
ds.lt_di[["predicted_class"]] = 0
ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Works out the proportion correct
proportion_correct <- nrow(ds.lt_di[correct_items,])/nrow(ds.lt_di)
# Logistic Regression Model fit
glm_fit <-glm(digit ~ V11, data = ds.lt_di, family = 'binomial')
# Works the predicted value based on the model created
ds.lt_di[["predicted_val"]] = predict(glm_fit, ds.lt_di, type="response")
# Zeroes out a predicted class field and then predicts based on a predicted value of 05
ds.lt_di[["predicted_class"]] = 0
ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Works out the proportion correct
proportion_correct <- nrow(ds.lt_di[correct_items,])/nrow(ds.lt_di)
# Logistic Regression Model fit
glm_fit <-glm(digit ~ V12, data = ds.lt_di, family = 'binomial')
# Works the predicted value based on the model created
ds.lt_di[["predicted_val"]] = predict(glm_fit, ds.lt_di, type="response")
# Zeroes out a predicted class field and then predicts based on a predicted value of 05
ds.lt_di[["predicted_class"]] = 0
ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Works out the proportion correct
proportion_correct <- nrow(ds.lt_di[correct_items,])/nrow(ds.lt_di)
# Logistic Regression Model fit
glm_fit <-glm(digit ~ V13, data = ds.lt_di, family = 'binomial')
# Works the predicted value based on the model created
ds.lt_di[["predicted_val"]] = predict(glm_fit, ds.lt_di, type="response")
# Zeroes out a predicted class field and then predicts based on a predicted value of 05
ds.lt_di[["predicted_class"]] = 0
ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Works out the proportion correct
proportion_correct <- nrow(ds.lt_di[correct_items,])/nrow(ds.lt_di)
# Works out the proportion incorrect
proportion_incorrect <- nrow(ds.lt_di[!correct_items,])/nrow(ds.lt_di)
# Logistic Regression Model fit
glm_fit <-glm(digit ~ V14, data = ds.lt_di, family = 'binomial')
# Works the predicted value based on the model created
ds.lt_di[["predicted_val"]] = predict(glm_fit, ds.lt_di, type="response")
# Zeroes out a predicted class field and then predicts based on a predicted value of 05
ds.lt_di[["predicted_class"]] = 0
ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Works out the proportion correct
proportion_correct <- nrow(ds.lt_di[correct_items,])/nrow(ds.lt_di)
# Logistic Regression Model fit
glm_fit <-glm(digit ~ V15, data = ds.lt_di, family = 'binomial')
# Works the predicted value based on the model created
ds.lt_di[["predicted_val"]] = predict(glm_fit, ds.lt_di, type="response")
# Zeroes out a predicted class field and then predicts based on a predicted value of 05
ds.lt_di[["predicted_class"]] = 0
ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Works out the proportion correct
proportion_correct <- nrow(ds.lt_di[correct_items,])/nrow(ds.lt_di)
# Logistic Regression Model fit
glm_fit <-glm(digit ~ V16, data = ds.lt_di, family = 'binomial')
# Works the predicted value based on the model created
ds.lt_di[["predicted_val"]] = predict(glm_fit, ds.lt_di, type="response")
# Zeroes out a predicted class field and then predicts based on a predicted value of 05
ds.lt_di[["predicted_class"]] = 0
ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Works out the proportion correct
proportion_correct <- nrow(ds.lt_di[correct_items,])/nrow(ds.lt_di)
# Works out the proportion incorrect
proportion_incorrect <- nrow(ds.lt_di[!correct_items,])/nrow(ds.lt_di)
# Results table to plot
proportion <- c("correct", "incorrect")
# Logistic Regression Model fit
glm_fit <-glm(digit ~ V17, data = ds.lt_di, family = 'binomial')
# Works the predicted value based on the model created
ds.lt_di[["predicted_val"]] = predict(glm_fit, ds.lt_di, type="response")
# Zeroes out a predicted class field and then predicts based on a predicted value of 05
ds.lt_di[["predicted_class"]] = 0
ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Works out the proportion correct
proportion_correct <- nrow(ds.lt_di[correct_items,])/nrow(ds.lt_di)
# Logistic Regression Model fit
glm_fit <-glm(digit ~ V18, data = ds.lt_di, family = 'binomial')
# Works the predicted value based on the model created
ds.lt_di[["predicted_val"]] = predict(glm_fit, ds.lt_di, type="response")
# Zeroes out a predicted class field and then predicts based on a predicted value of 05
ds.lt_di[["predicted_class"]] = 0
ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Works out the proportion correct
proportion_correct <- nrow(ds.lt_di[correct_items,])/nrow(ds.lt_di)
# Logistic Regression Model fit
glm_fit <-glm(digit ~ V19, data = ds.lt_di, family = 'binomial')
# Works the predicted value based on the model created
ds.lt_di[["predicted_val"]] = predict(glm_fit, ds.lt_di, type="response")
# Zeroes out a predicted class field and then predicts based on a predicted value of 05
ds.lt_di[["predicted_class"]] = 0
ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Works out the proportion correct
proportion_correct <- nrow(ds.lt_di[correct_items,])/nrow(ds.lt_di)
# Works out the proportion incorrect
proportion_incorrect <- nrow(ds.lt_di[!correct_items,])/nrow(ds.lt_di)
# Logistic Regression Model fit
glm_fit <-glm(digit ~ V20, data = ds.lt_di, family = 'binomial')
# Works the predicted value based on the model created
ds.lt_di[["predicted_val"]] = predict(glm_fit, ds.lt_di, type="response")
# Zeroes out a predicted class field and then predicts based on a predicted value of 05
ds.lt_di[["predicted_class"]] = 0
ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Logistic Regression Model fit
glm_fit <-glm(digit ~ V18, data = ds.lt_di, family = 'binomial')
# Works the predicted value based on the model created
ds.lt_di[["predicted_val"]] = predict(glm_fit, ds.lt_di, type="response")
# Zeroes out a predicted class field and then predicts based on a predicted value of 05
ds.lt_di[["predicted_class"]] = 0
ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Works out the proportion correct
proportion_correct <- nrow(ds.lt_di[correct_items,])/nrow(ds.lt_di)
# Works out the proportion incorrect
proportion_incorrect <- nrow(ds.lt_di[!correct_items,])/nrow(ds.lt_di)
# Results table to plot
proportion <- c("correct", "incorrect")
values <- c(proportion_correct, proportion_incorrect)
results <- data.frame(proportion, values)
# Plot histogram of results
ggplot(results, aes(x = proportion, y = values)) + geom_bar(position = 'dodge', stat="identity") + geom_text(aes(label=values), position=position_dodge(width=0.9), vjust=-0.25)
# Change workspace to section_code and then saves plot
setwd(section_code.location)
ggsave("part1_accuracy_graph.png")
# Library Imports
library(ggplot2)
set.seed(3060)
# Working Directory & Code Directory
training_set.location <- "/Users/thomaspickup/Documents/University/CSC3060/Assignments/Assignment2_40145342/section1_code"
section_code.location <- "/Users/thomaspickup/Documents/University/CSC3060/Assignments/Assignment2_40145342/section1_code"
setwd(training_set.location)
# Import features CSV
ds <- read.table("40145342_features.csv", header=FALSE, sep=",")
# Next we create the dataframe
ds.df <- data.frame(ds)
# We can now split the data into subsets based upon the label
ds.lt_di <- subset(ds.df, V1 < 30)
ds.lt <- subset(ds.df, V1 < 20)
ds.di <- subset(ds.df, V1 > 20 & V1 < 30)
ds.ma <- subset(ds.df, V1 > 30)
# Now we add a column denoting whether something is a digit
# If digit column is 1 then the row contains a digit else its a letter
ds.lt_di$digit <- 0
ds.lt_di$digit[ds.lt_di$V1 > 20] <- 1
# Finally lets shuffle the dataset and break it into folds
kfolds <- 7
ds.lt_di <- ds.lt_di[sample(nrow(ds.lt_di)),]
ds.lt_di$folds <- cut(seq(1,nrow(ds.lt_di)),breaks=kfolds,labels=FALSE)
# Logistic Regression Model fit
glm_part2_fit <-glm(digit ~ V3 + V4 + V5 + V6 + V8 + V9 + V10 + V11, data = ds.lt_di, family = 'binomial')
glm_part1_fit <-glm(digit ~ V18, data = ds.lt_di, family = 'binomial')
## First re run part 1's model with CV
k_accuracy_correct = c()
k_accuracy_incorrect = c()
for(i in 1:kfolds) {
# Works the predicted value based on the model created
ds.lt_di[["predicted_val"]] = predict(glm_part1_fit, ds.lt_di$folds == i, type="response")
# Zeroes out a predicted class field and then predicts based on a predicted value of 05
ds.lt_di[["predicted_class"]] = 0
ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Works out the proportion correct
proportion_correct <- nrow(ds.lt_di[correct_items,])/nrow(ds.lt_di)
k_accuracy_correct <- cbind(k_accuracy_correct, proportion_correct)
k_accuracy_incorrect <- cbind(k_accuracy_incorrect, proportion_incorrect)
}
# Library Imports
library(ggplot2)
set.seed(3060)
# Working Directory & Code Directory
training_set.location <- "/Users/thomaspickup/Documents/University/CSC3060/Assignments/Assignment2_40145342/section1_code"
section_code.location <- "/Users/thomaspickup/Documents/University/CSC3060/Assignments/Assignment2_40145342/section1_code"
setwd(training_set.location)
# Import features CSV
ds <- read.table("40145342_features.csv", header=FALSE, sep=",")
# Next we create the dataframe
ds.df <- data.frame(ds)
# We can now split the data into subsets based upon the label
ds.lt_di <- subset(ds.df, V1 < 30)
ds.lt <- subset(ds.df, V1 < 20)
ds.di <- subset(ds.df, V1 > 20 & V1 < 30)
ds.ma <- subset(ds.df, V1 > 30)
# Now we add a column denoting whether something is a digit
# If digit column is 1 then the row contains a digit else its a letter
ds.lt_di$digit <- 0
ds.lt_di$digit[ds.lt_di$V1 > 20] <- 1
# Finally lets shuffle the dataset and break it into folds
kfolds <- 7
ds.lt_di <- ds.lt_di[sample(nrow(ds.lt_di)),]
ds.lt_di$folds <- cut(seq(1,nrow(ds.lt_di)),breaks=kfolds,labels=FALSE)
# Logistic Regression Model fit
glm_part2_fit <-glm(digit ~ V3 + V4 + V5 + V6 + V8 + V9 + V10 + V11, data = ds.lt_di, family = 'binomial')
glm_part1_fit <-glm(digit ~ V18, data = ds.lt_di, family = 'binomial')
## First re run part 1's model with CV
k_accuracy_correct = c()
k_accuracy_incorrect = c()
for(i in 1:kfolds) {
# Works the predicted value based on the model created
ds.lt_di[["predicted_val"]] = predict(glm_part1_fit, ds.lt_di[ds.lt_di$folds == i], type="response")
# Zeroes out a predicted class field and then predicts based on a predicted value of 05
ds.lt_di[["predicted_class"]] = 0
ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Works out the proportion correct
proportion_correct <- nrow(ds.lt_di[correct_items,])/nrow(ds.lt_di)
k_accuracy_correct <- cbind(k_accuracy_correct, proportion_correct)
k_accuracy_incorrect <- cbind(k_accuracy_incorrect, proportion_incorrect)
}
for(i in 1:kfolds) {
# Works the predicted value based on the model created
ds.lt_di[["predicted_val"]] = predict(glm_part2_fit, ds.lt_di[ds.lt_di$folds == i], type="response")
# Zeroes out a predicted class field and then predicts based on a predicted value of 05
ds.lt_di[["predicted_class"]] = 0
ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Works out the proportion correct
proportion_correct <- nrow(ds.lt_di[correct_items,])/nrow(ds.lt_di)
k_accuracy_correct <- cbind(k_accuracy_correct, proportion_correct)
k_accuracy_incorrect <- cbind(k_accuracy_incorrect, proportion_incorrect)
}
for(i in 1:kfolds) {
# Works the predicted value based on the model created
ds.lt_di[["predicted_val"]] = predict(glm_part2_fit, ds.lt_di[ds.lt_di$folds == i], type="response")
# Zeroes out a predicted class field and then predicts based on a predicted value of 05
ds.lt_di[["predicted_class"]] = 0
ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Works out the proportion correct
proportion_correct <- nrow(ds.lt_di[correct_items,])/nrow(ds.lt_di)
# Works out the proportion incorrect
proportion_incorrect <- nrow(ds.lt_di[!correct_items,])/nrow(ds.lt_di)
k_accuracy_correct <- cbind(k_accuracy_correct, proportion_correct)
k_accuracy_incorrect <- cbind(k_accuracy_incorrect, proportion_incorrect)
}
# Library Imports
library(ggplot2)
set.seed(3060)
# Working Directory & Code Directory
training_set.location <- "/Users/thomaspickup/Documents/University/CSC3060/Assignments/Assignment2_40145342/section1_code"
section_code.location <- "/Users/thomaspickup/Documents/University/CSC3060/Assignments/Assignment2_40145342/section1_code"
setwd(training_set.location)
# Import features CSV
ds <- read.table("40145342_features.csv", header=FALSE, sep=",")
# Next we create the dataframe
ds.df <- data.frame(ds)
# We can now split the data into subsets based upon the label
ds.lt_di <- subset(ds.df, V1 < 30)
ds.lt <- subset(ds.df, V1 < 20)
ds.di <- subset(ds.df, V1 > 20 & V1 < 30)
ds.ma <- subset(ds.df, V1 > 30)
# Now we add a column denoting whether something is a digit
# If digit column is 1 then the row contains a digit else its a letter
ds.lt_di$digit <- 0
ds.lt_di$digit[ds.lt_di$V1 > 20] <- 1
# Finally lets shuffle the dataset and break it into folds
kfolds <- 7
ds.lt_di <- ds.lt_di[sample(nrow(ds.lt_di)),]
ds.lt_di$folds <- cut(seq(1,nrow(ds.lt_di)),breaks=kfolds,labels=FALSE)
# Logistic Regression Model fit
glm_part2_fit <-glm(digit ~ V3 + V4 + V5 + V6 + V8 + V9 + V10 + V11, data = ds.lt_di, family = 'binomial')
glm_part1_fit <-glm(digit ~ V18, data = ds.lt_di, family = 'binomial')
## First re run part 1's model with CV
k_accuracy_correct = c()
k_accuracy_incorrect = c()
for(i in 1:kfolds) {
# Works the predicted value based on the model created
ds.lt_di[["predicted_val"]] = predict(glm_part2_fit, ds.lt_di[ds.lt_di$folds == i], type="response")
# Zeroes out a predicted class field and then predicts based on a predicted value of 05
ds.lt_di[["predicted_class"]] = 0
ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Works out the proportion correct
proportion_correct <- nrow(ds.lt_di[correct_items,])/nrow(ds.lt_di)
# Works out the proportion incorrect
proportion_incorrect <- nrow(ds.lt_di[!correct_items,])/nrow(ds.lt_di)
k_accuracy_correct <- cbind(k_accuracy_correct, proportion_correct)
k_accuracy_incorrect <- cbind(k_accuracy_incorrect, proportion_incorrect)
}
for(i in 1:kfolds) {
# Works the predicted value based on the model created
ds.lt_di[["predicted_val"]] = predict(glm_part2_fit, ds.lt_di[ds.lt_di$folds == i,], type="response")
# Zeroes out a predicted class field and then predicts based on a predicted value of 05
ds.lt_di[["predicted_class"]] = 0
ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Works out the proportion correct
proportion_correct <- nrow(ds.lt_di[correct_items,])/nrow(ds.lt_di)
# Works out the proportion incorrect
proportion_incorrect <- nrow(ds.lt_di[!correct_items,])/nrow(ds.lt_di)
k_accuracy_correct <- cbind(k_accuracy_correct, proportion_correct)
k_accuracy_incorrect <- cbind(k_accuracy_incorrect, proportion_incorrect)
}
part1_correct = mean(k_accuracy_correct)
part1_incorrect = mean(k_accuracy_incorrect)
# Library Imports
library(ggplot2)
set.seed(3060)
# Working Directory & Code Directory
training_set.location <- "/Users/thomaspickup/Documents/University/CSC3060/Assignments/Assignment2_40145342/section1_code"
section_code.location <- "/Users/thomaspickup/Documents/University/CSC3060/Assignments/Assignment2_40145342/section1_code"
setwd(training_set.location)
# Import features CSV
ds <- read.table("40145342_features.csv", header=FALSE, sep=",")
# Next we create the dataframe
ds.df <- data.frame(ds)
# We can now split the data into subsets based upon the label
ds.lt_di <- subset(ds.df, V1 < 30)
ds.lt <- subset(ds.df, V1 < 20)
ds.di <- subset(ds.df, V1 > 20 & V1 < 30)
ds.ma <- subset(ds.df, V1 > 30)
# Now we add a column denoting whether something is a digit
# If digit column is 1 then the row contains a digit else its a letter
ds.lt_di$digit <- 0
ds.lt_di$digit[ds.lt_di$V1 > 20] <- 1
# Finally lets shuffle the dataset and break it into folds
kfolds <- 7
ds.lt_di <- ds.lt_di[sample(nrow(ds.lt_di)),]
ds.lt_di$folds <- cut(seq(1,nrow(ds.lt_di)),breaks=kfolds,labels=FALSE)
# Logistic Regression Model fit
glm_part2_fit <-glm(digit ~ V3 + V4 + V5 + V6 + V8 + V9 + V10 + V11, data = ds.lt_di, family = 'binomial')
glm_part1_fit <-glm(digit ~ V18, data = ds.lt_di, family = 'binomial')
## First re run part 1's model with CV
k_accuracy_correct = c()
k_accuracy_incorrect = c()
for(i in 1:kfolds) {
# Works the predicted value based on the model created
ds.lt_di[["predicted_val"]] = predict(glm_part1_fit, ds.lt_di[ds.lt_di$folds == i,], type="response")
# Zeroes out a predicted class field and then predicts based on a predicted value of 05
ds.lt_di[["predicted_class"]] = 0
ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Works out the proportion correct
proportion_correct <- nrow(ds.lt_di[correct_items,])/nrow(ds.lt_di)
# Works out the proportion incorrect
proportion_incorrect <- nrow(ds.lt_di[!correct_items,])/nrow(ds.lt_di)
print(proportion_correct)
k_accuracy_correct <- cbind(k_accuracy_correct, proportion_correct)
k_accuracy_incorrect <- cbind(k_accuracy_incorrect, proportion_incorrect)
}
part1_correct = mean(k_accuracy_correct)
part1_incorrect = mean(k_accuracy_incorrect)
# Results table to plot
proportion <- c("correct", "incorrect")
values <- c(part1_correct, part1_incorrect)
results <- data.frame(proportion, values)
# Plot histogram of results
ggplot(results, aes(x = proportion, y = values)) + geom_bar(position = 'dodge', stat="identity") + geom_text(aes(label=values), position=position_dodge(width=0.9), vjust=-0.25)
# Change workspace to section_code and then saves plot
setwd(section_code.location)
ggsave("part1_accuracy_graph_cv.png")
setwd(training_set.location)
# Now lets re run part 2's fit
k_accuracy_correct = c()
k_accuracy_incorrect = c()
for(i in 1:kfolds) {
# Works the predicted value based on the model created
ds.lt_di[["predicted_val"]] = predict(glm_part2_fit, ds.lt_di[ds.lt_di$folds == i,], type="response")
# Zeroes out a predicted class field and then predicts based on a predicted value of 05
ds.lt_di[["predicted_class"]] = 0
ds.lt_di[["predicted_class"]][ds.lt_di[["predicted_val"]] > 0.5] = 1
# Looks to see how many correct guesses there are
correct_items = ds.lt_di[["predicted_class"]] == ds.lt_di[["digit"]]
# Works out the proportion correct
proportion_correct <- nrow(ds.lt_di[correct_items,])/nrow(ds.lt_di)
# Works out the proportion incorrect
proportion_incorrect <- nrow(ds.lt_di[!correct_items,])/nrow(ds.lt_di)
k_accuracy_correct <- cbind(k_accuracy_correct, proportion_correct)
k_accuracy_incorrect <- cbind(k_accuracy_incorrect, proportion_incorrect)
}
part2_correct = mean(k_accuracy_correct)
part2_incorrect = mean(k_accuracy_incorrect)
# Results table to plot
proportion <- c("correct", "incorrect")
values <- c(part2_correct, part2_incorrect)
results <- data.frame(proportion, values)
# Plot histogram of results
ggplot(results, aes(x = proportion, y = values)) + geom_bar(position = 'dodge', stat="identity") + geom_text(aes(label=values), position=position_dodge(width=0.9), vjust=-0.25)
# Change workspace to section_code and then saves plot
setwd(section_code.location)
ggsave("part2_accuracy_graph_cv.png")
# Finally lets shuffle the dataset and break it into folds
kfolds <- 5
set.seed(3060)
# Sets the location variables and the working directory
training_set.location <- "/Users/thomaspickup/Documents/University/CSC3060/Assignments/Assignment2_40145342/training_dataset"
section_code.location <- "/Users/thomaspickup/Documents/University/CSC3060/Assignments/Assignment2_40145342/section2_code"
setwd(training_set.location)
# Finds all the CSV files in that path with the suffix features.csv
training_set.files <- list.files(pattern="*features.csv")
# Goes through the list of files and imports the data into training_set.data
training_set.data <- list()
for (i in 1:length(training_set.files)) {
training_set.data[[i]] <- read.csv(training_set.files[i], header=FALSE, sep=",")
}
# Calls RBind on training_set.data and creates one dataframe from the individual ones
training_set.dataframe <- do.call(rbind, training_set.data)
# Imports the classes needed for classification and plotting
library(class)
library(ggplot2)
# Makes a training set of indexes lower than 6
training_set <- (training_set.dataframe$V2<6)
# Gets the values of the rows of all the rows selected above for the training set
training_set.x <- cbind(training_set.dataframe$V3,training_set.dataframe$V4,training_set.dataframe$V5,training_set.dataframe$V6,training_set.dataframe$V7,training_set.dataframe$V8,training_set.dataframe$V9,training_set.dataframe$V10,training_set.dataframe$V11,training_set.dataframe$V12)[training_set,]
# Stores the rows not selected for the training set in the test set
test_set.x <- cbind(training_set.dataframe$V3,training_set.dataframe$V4,training_set.dataframe$V5,training_set.dataframe$V6,training_set.dataframe$V7,training_set.dataframe$V8,training_set.dataframe$V9,training_set.dataframe$V10,training_set.dataframe$V11,training_set.dataframe$V12)[!training_set,]
# Gets the labels for the test and training sets
training_set.labels <- training_set.dataframe$V1[training_set]
test_set.labels <- training_set.dataframe$V1[!training_set]
# Stores the values of K to test and creates a blank list for the accuracies
ks = c(1,3,5,7,9,11,15,19,23,31)
accuracies = c()
# Runs the KNN algorithm for all values of K above and stores the accuracy of each value of K
for (k in ks){
knn.pred=knn(training_set.x,test_set.x,training_set.labels,k=k)
table(knn.pred,test_set.labels)
accuracies = cbind(accuracies, mean(knn.pred==test_set.labels))
}
# Plots as a bar chart
accuracies.dataframe = as.data.frame(t(accuracies))
cbind(accuracies.dataframe, ks)
ggplot(accuracies.dataframe, aes(x=ks, y=V1)) + geom_bar(stat = "identity")
setwd(section_code.location)
ggsave("part1_accuracy_graph.png")
View(accuracies.dataframe)
View(accuracies.dataframe)
View(accuracies)
View(results)
accuracies.dataframe = cbind(accuracies.dataframe, ks)
View(accuracies.dataframe)
set.seed(3060)
# Sets the location variables and the working directory
training_set.location <- "/Users/thomaspickup/Documents/University/CSC3060/Assignments/Assignment2_40145342/training_dataset"
section_code.location <- "/Users/thomaspickup/Documents/University/CSC3060/Assignments/Assignment2_40145342/section2_code"
setwd(training_set.location)
# Finds all the CSV files in that path with the suffix features.csv
training_set.files <- list.files(pattern="*features.csv")
# Goes through the list of files and imports the data into training_set.data
training_set.data <- list()
for (i in 1:length(training_set.files)) {
training_set.data[[i]] <- read.csv(training_set.files[i], header=FALSE, sep=",")
}
# Calls RBind on training_set.data and creates one dataframe from the individual ones
training_set.dataframe <- do.call(rbind, training_set.data)
# Imports the classes needed for classification and plotting
library(class)
library(ggplot2)
kfoldsk <- 5
training_set.dataframe <- training_set.dataframe[sample(nrow(training_set.dataframe)),]
training_set.dataframe$folds <- cut(seq(1,nrow(training_set.dataframe)),breaks=kfoldsk,labels=FALSE)
fs = c("V3", "V4", "V5", "V6", "V7", "V8", "V9", "V10", "V11", "V12")
ks = c(1,3,5,7,9,11,15,19,23,31)
accuracies = c()
for (knnk in ks) {
k_accuracies = c()
for(i in 1:kfoldsk) {
training_set.this_fold  = training_set.dataframe[training_set.dataframe$folds != i,]
test_set.this_fold = training_set.dataframe[training_set.dataframe$folds == i,]
# fit knn model on this fold
knn.pred = knn(training_set.this_fold[,fs], test_set.this_fold[,fs], training_set.this_fold$V1, k=knnk)
correct_list = knn.pred == test_set.this_fold$V1
nr_correct = nrow(test_set.this_fold[correct_list,])
this_acc_rate = nr_correct/nrow(test_set.this_fold)
k_accuracies <- cbind(k_accuracies, this_acc_rate)
}
accuracies = cbind(accuracies, mean(k_accuracies))
}
accuracies = t(accuracies)
View(accuracies.dataframe)
accuracies = cbind(accuracies, ks)
View(accuracies.dataframe)
# Plots as a bar chart
accuracies.dataframe = as.data.frame(accuracies)
View(accuracies.dataframe)
